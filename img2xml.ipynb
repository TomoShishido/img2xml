{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLO_yo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github.com/TomoShishido/img2xml/blob/main/img2xml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["# img2xml: produce a music xml file from a sheet music image (.jpg or .png)"]},{"cell_type":"code","metadata":{"id":"29iNHiUMSVIf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613232997899,"user_tz":-540,"elapsed":11856,"user":{"displayName":"Haru Tomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKa35SIZWrRT1Kcx9yonqyusjGk5B98FHeMoZpzQ=s64","userId":"06160437493041457037"}},"outputId":"79557a5e-cf54-4025-c925-f4b2e8bda8d3"},"source":["\n","!git clone https://github.com/TomoShishido/img2xml  # clone repo\n","!pip install -qr img2xml/bfaaap/yolov5/requirements.txt  # install dependencies (ignore errors)\n","%cd /content/img2xml/bfaaap/yolov5\n","\n","import torch\n","from IPython.display import Image, clear_output  # to display images\n","from utils.google_utils import gdrive_download  # to download models/datasets\n","\n","clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Setup complete. Using torch 1.7.0+cu101 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16160MB, multi_processor_count=80)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Awt1uv6pKXII","executionInfo":{"status":"ok","timestamp":1613233001077,"user_tz":-540,"elapsed":1238,"user":{"displayName":"Haru Tomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKa35SIZWrRT1Kcx9yonqyusjGk5B98FHeMoZpzQ=s64","userId":"06160437493041457037"}},"outputId":"54c216fd-415e-4d94-f3b7-e83876e14a6d"},"source":["!ls -l /content/img2xml/bfaaap/"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: /content/img2xml/bfaaap/: No such file or directory\n"]}]},{"cell_type":"code","metadata":{"id":"Kl6vNZMDUZSS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613233039701,"user_tz":-540,"elapsed":26409,"user":{"displayName":"Haru Tomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKa35SIZWrRT1Kcx9yonqyusjGk5B98FHeMoZpzQ=s64","userId":"06160437493041457037"}},"outputId":"a5b38382-9bd5-4ab3-8aa6-47fd35b06c7b"},"source":["from google.colab import drive\n","drive.mount('/content/g')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/g\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c7H8ZIjkgLHm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613233043142,"user_tz":-540,"elapsed":1779,"user":{"displayName":"Haru Tomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKa35SIZWrRT1Kcx9yonqyusjGk5B98FHeMoZpzQ=s64","userId":"06160437493041457037"}},"outputId":"04e6a0eb-4f0c-4f9c-bae1-969c9a4a3308"},"source":["!ls /content/g/"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: /content/g/: No such file or directory\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# place yolov5 weights in /bfaaap/yolov5/weightsstock/\n","!mkdir /content/img2xml/bfaaap/yolov5/weightsstock\n","%cd /content/img2xml/bfaaap/yolov5/weightsstock\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hTrPCL30Xbi9-qHyqb2lAcI_FoFdk0HK' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1hTrPCL30Xbi9-qHyqb2lAcI_FoFdk0HK\" -O img2xml_weights.zip && rm -rf /tmp/cookies.txt\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip img2xml_weights.zip"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import glob\n","import os\n","import subprocess\n","import shutil\n","import numpy as np\n","import math\n","from enum import Enum, auto\n","import copy\n","from itertools import chain\n","import time\n","import subprocess\n","\n","%cd /content/img2xml/bfaaap/yolov5\n","\n","#here, provide a FILE_PATH for a sheet music image (either .jpg or .png)\n","FILE_PATH ='/content/img2xml/bfaaap/musicdata/test0/sarabandePhotoInclined.jpg'"]},{"cell_type":"code","metadata":{"id":"fxadpFisdb96","executionInfo":{"status":"ok","timestamp":1613236087822,"user_tz":-540,"elapsed":2142,"user":{"displayName":"Haru Tomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKa35SIZWrRT1Kcx9yonqyusjGk5B98FHeMoZpzQ=s64","userId":"06160437493041457037"}}},"source":["#First, level the original sheet music image\n","%cd /content/img2xml/bfaaap\n","from leveloriginalimg.leveloriginalimg import leveloriginalimg\n","\n","FILE_PATH = leveloriginalimg(FILE_PATH)"],"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Image(filename=FILE_PATH, width=900) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#extract staves with measures\n","#perform inference on sheet music\n","%cd /content/img2xml/bfaaap/yolov5\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff'\n","\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.95_staff4_20201230.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.75', '--source', FILE_PATH, '--save-txt'])\n","proc.wait()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# check the measure inference result\n","files_temp = glob.glob(FILE_PATH)\n","#the resulting file after inference of measures\n","MEASURE_INFERENCE_RESULT_PATH = ''\n","for file_temp in files_temp:\n","    if file_temp.endswith('jpg') or file_temp.endswith('png'):\n","        basename = os.path.basename(file_temp)\n","        MEASURE_INFERENCE_RESULT_PATH = SAVE_DIRECTORY_PATH + '/' + basename\n","\n","Image(filename=MEASURE_INFERENCE_RESULT_PATH, width=900) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#After the measure-recognizing model is applied to a piece of sheet music\n","\n","#copy and move the relevant files under a dirctory ./musicdata/AAA/(staff/labels)\n","#sheet music (.jpg) provided in FILE_PATH\n","files_temp = glob.glob(FILE_PATH)\n","#To skip .txt files\n","for file_temp in files_temp:\n","    if file_temp.endswith('jpg') or file_temp.endswith('png'):\n","        img = cv2.imread(file_temp)\n","        dirname = os.path.dirname(file_temp)\n","        basename = os.path.basename(file_temp)\n","        cv2.imwrite(dirname + '/staff/labels/' + basename, img)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#generate measures \n","%cd /content/img2xml/bfaaap\n","from alignmeasures.align_measures import generate_measures_in_eachstave_aslist\n","#sheet music provided in FILE_PATH\n","staves_with_measures_in_sheetmusic = generate_measures_in_eachstave_aslist(FILE_PATH)\n","print(f'the number of staves_with_measures_in_sheetmusic is {len(staves_with_measures_in_sheetmusic)}')\n","for i, each_staff in enumerate(staves_with_measures_in_sheetmusic):\n","    print(f'the number of measures in staff{i} is {len(each_staff)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#input whether staves are paired\n","areStavesPaired = True\n","\n","#excise and enlarge each measure img at 412 x 412 pixels in each staff and stored in musicdata/AAA/measure/staff1/ or staff2/\n","from enlargemeasures.enlargeeachmeasure import produceResizedMeasuresFromAlignedStaves\n","#in the case of wide staff extraction, set staff_magnification = 1.2\n","staff_magnification = 1.2\n","\n","produceResizedMeasuresFromAlignedStaves(img_FILE_PATH=FILE_PATH, aligned_staves=staves_with_measures_in_sheetmusic, isPaired=areStavesPaired, upper_margin=staff_magnification, lower_margin=staff_magnification)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#level again each measure one by one\n","from leveloriginalimg.leveloriginalimg import leveleachmeasure\n","\n","MEASURES_STAFF1_PATH = os.path.dirname(FILE_PATH) + '/measure/staff1/*'\n","files_temp = glob.glob(MEASURES_STAFF1_PATH)\n","for file_temp in files_temp:\n","    if file_temp.endswith('jpg') or file_temp.endswith('png'):\n","        FILE_DIR_PATH = os.path.dirname(file_temp)\n","        FILE_BASENAME = os.path.basename(file_temp)\n","        THIS_PATH = FILE_DIR_PATH + '/' + FILE_BASENAME\n","        result0 = leveleachmeasure(THIS_PATH)\n","\n","MEASURES_STAFF2_PATH = os.path.dirname(FILE_PATH) + '/measure/staff2/*'\n","files_temp = glob.glob(MEASURES_STAFF2_PATH)\n","for file_temp in files_temp:\n","    if file_temp.endswith('jpg') or file_temp.endswith('png'):\n","        FILE_DIR_PATH = os.path.dirname(file_temp)\n","        FILE_BASENAME = os.path.basename(file_temp)\n","        THIS_PATH = FILE_DIR_PATH + '/' + FILE_BASENAME\n","        leveleachmeasure(THIS_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#apply individual models to the measures selected for staff 1 or 2\n","\n","#work at the yolov5 directory\n","%cd /content/img2xml/bfaaap/yolov5\n","\n","#processes in parallel\n","start = time.time()\n","print(start)\n","processes = []\n","\n","\n","# FILE_PATH ='/Users/tomoimacpro/TSh_project/bfaaap/musicdata/testfordetection1/PatheticMov2_1.jpg'\n","#image source directory path for either staff1 or staff2\n","\n","\n","#For staff1\n","\n","\n","SOURCE_PATH = os.path.dirname(FILE_PATH) + '/measure/staff1/*'\n","\n","#body\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff1/body'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.94_body4_20210208.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((0, proc))\n","#armbeam\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff1/armbeam'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.99_armbeam2_20210214.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((1, proc))\n","#accidental\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff1/accidental'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.99_Accidental2_20210209.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((2, proc))\n","#rest\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff1/rest'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.99_rest1_20210107.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((3, proc))\n","#clef\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff1/clef'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.99_Clef3_20210129.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((4, proc))\n","\n","#For staff2\n","\n","SOURCE_PATH = os.path.dirname(FILE_PATH) + '/measure/staff2/*'\n","\n","#body\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff2/body'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.94_body4_20210208.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((5, proc))\n","#armbeam\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff2/armbeam'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.99_armbeam2_20210214.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((6, proc))\n","#accidental\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff2/accidental'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.99_Accidental2_20210209.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((7, proc))\n","#rest\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff2/rest'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.99_rest1_20210107.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((8, proc))\n","#clef\n","SAVE_DIRECTORY_PATH = os.path.dirname(FILE_PATH) + '/staff2/clef'\n","proc = subprocess.Popen(['python','detect.py', '--weights', '/content/img2xml/bfaaap/yolov5/weightsstock/last_0.99_Clef3_20210129.pt', '--SAVE_PATH', SAVE_DIRECTORY_PATH ,'--img', '416', '--conf', '0.60', '--source', SOURCE_PATH, '--save-txt'])\n","# proc.wait()\n","processes.append((9, proc))\n","\n","for i, p in processes:\n","    print(f'waiting process {i} to finish')\n","    p.wait()\n","\n","#end the time measurement\n","elapsed_time = time.time() - start\n","print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#check some of the inference results\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","def show_images(images, figsize=(10,10), columns = 4):\n","  plt.figure(figsize=figsize)\n","  for i, image in enumerate(images):\n","      plt.subplot(len(images) / columns + 1, columns, i + 1)\n","      plt.imshow(image)\n","images = []\n","#change /test0/ to your folder of interest\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/body/measure#000.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/body/measure#001.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/body/measure#002.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/body/measure#003.jpg')\n","images.append(img)\n","\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/armbeam/measure#000.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/armbeam/measure#001.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/armbeam/measure#002.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/armbeam/measure#003.jpg')\n","images.append(img)\n","\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/clef/measure#000.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/clef/measure#001.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/clef/measure#002.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/clef/measure#003.jpg')\n","images.append(img)\n","\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/accidental/measure#000.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/accidental/measure#001.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/accidental/measure#002.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/accidental/measure#003.jpg')\n","images.append(img)\n","\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/rest/measure#000.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/rest/measure#001.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/rest/measure#002.jpg')\n","images.append(img)\n","img = Image.open('/content/img2xml/bfaaap/musicdata/test0/staff1/rest/measure#003.jpg')\n","images.append(img)\n","\n","show_images(images)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#get the file path, basename, extention\n","\n","files_temp = glob.glob(FILE_PATH) #\"./tmp/*\":beforehand prepare images and Yolov5 anotation files in ./tmp/subdirectory\n","#To skip .txt files\n","FILE_DIR_PATH = ''\n","FILE_BASENAME = ''\n","FILE_BASENAME_WITHOUTEXT = ''\n","for file_temp in files_temp:\n","    if file_temp.endswith('jpg') or file_temp.endswith('png'):\n","        img = cv2.imread(file_temp)\n","        FILE_DIR_PATH = os.path.dirname(file_temp)\n","        FILE_BASENAME = os.path.basename(file_temp)\n","        FILE_BASENAME_WITHOUTEXT = os.path.splitext(FILE_BASENAME)[0]\n","        cv2.imwrite(FILE_DIR_PATH + '/staff/labels/' + FILE_BASENAME, img)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd /content/img2xml/bfaaap\n","from alignmeasures.align_measures import generate_measures_in_eachstave_aslist\n","#sheet music provided in FILE_PATH\n","staves_with_measures_in_sheetmusic = generate_measures_in_eachstave_aslist(FILE_PATH)\n","print(f'the number of staves_with_measures_in_sheetmusic is {len(staves_with_measures_in_sheetmusic)}')\n","for i, each_staff in enumerate(staves_with_measures_in_sheetmusic):\n","    print(f'the number of measures in staff{i} is {len(each_staff)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#input wheter staves are paired\n","areStavesPaired = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#generate ms sequence in each staff\n","\n","from makeyolomusicdict.generatedictforxml import give_all_ms_in_eachmeasure_for_staff1or2\n","\n","all_ms_in_eachmeasure_staff1, all_ms_in_eachmeasure_staff2 = give_all_ms_in_eachmeasure_for_staff1or2(isPaired=areStavesPaired, aligned_staves_input=staves_with_measures_in_sheetmusic, img_FILE_PATH=FILE_PATH)\n","print(f'the number of items in all_ms_in_eachmeasure_staff1 is {len(all_ms_in_eachmeasure_staff1)}')\n","aaa1 = all_ms_in_eachmeasure_staff1['measure#001']\n","print(f'aaa1 is {aaa1}')\n","print(f'the number of items in all_ms_in_eachmeasure_staff2 is {len(all_ms_in_eachmeasure_staff2)}')\n","bbb1 = all_ms_in_eachmeasure_staff2['measure#001']\n","print(f'bbb1 is {bbb1}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#input base data for sheet music of interest: the following is for sarabande by Handel\n","tempo = 120 #public data\n","beats = 3 #public data\n","beat_type = 2 #public data\n","preset_measure_duration = 1024 * beats / beat_type #public data\n","fifths = -1 #public data\n","staff = 1\n","\n","isWideStaff = False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from makeyolomusicdict.generatedictforxml import setCurrentAccidentalTable, generateMSsequenceForStaff1or2, Clef\n","\n","#classはimportすること\n","current_clef = Clef.G\n","current_accidental_table_template ={'A':'', 'B':'', 'C':'', 'D':'', 'E':'', 'F':'', 'G':''}\n","current_accidental_table = setCurrentAccidentalTable(current_accidental_table_template, fifths)\n","ms_sequenceOfInterest_staff1 = generateMSsequenceForStaff1or2(all_ms_in_eachmeasure_input=all_ms_in_eachmeasure_staff1, current_accidental_table_input=current_accidental_table, staff=1, current_clef_input=current_clef, preset_measure_duration=preset_measure_duration, FILE_PATH=FILE_PATH, isWideStaff=isWideStaff)\n","\n","#for staff2: check current_clef\n","current_clef = Clef.F\n","ms_sequenceOfInterest_staff2 = generateMSsequenceForStaff1or2(all_ms_in_eachmeasure_input=all_ms_in_eachmeasure_staff2, current_accidental_table_input=current_accidental_table, staff=2, current_clef_input=current_clef, preset_measure_duration=preset_measure_duration, FILE_PATH=FILE_PATH, isWideStaff=isWideStaff)\n","\n","print(f'the number of items in all_ms_in_eachmeasure_staff1 is {len(all_ms_in_eachmeasure_staff1)}')\n","print(f'the number of items in all_ms_in_eachmeasure_staff2 is {len(all_ms_in_eachmeasure_staff2)}')\n","\n","print(f'the number of items in ms_sequenceOfInterest_staff1 is {len(ms_sequenceOfInterest_staff1)}')\n","print(f'the number of items in ms_sequenceOfInterest_staff2 is {len(ms_sequenceOfInterest_staff2)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# generate a dictionary for ET\n","\n","from makeyolomusicdict.generatedictforxml import generateDictForET_singlestaff\n","\n","#for staff1\n","current_staff1_clef = Clef.G\n","dictionary_for_ET_staff1 = generateDictForET_singlestaff(ms_sequenceOfInterest_staff_input=ms_sequenceOfInterest_staff1, tempo=tempo, beats=beats, beat_type=beat_type, fifths=fifths, clef=current_staff1_clef)\n","part_content1 = dictionary_for_ET_staff1['part']\n","print(f'the number of items in dictionary_for_ET_staff1[0] is \\n{len(part_content1)}')\n","#for staff2\n","current_staff2_clef = Clef.F\n","dictionary_for_ET_staff2 = generateDictForET_singlestaff(ms_sequenceOfInterest_staff_input=ms_sequenceOfInterest_staff2, tempo=tempo, beats=beats, beat_type=beat_type, fifths=fifths, clef=current_staff2_clef)\n","part_content2 = dictionary_for_ET_staff2['part']\n","print(f'the number of items in dictionary_for_ET_staff2[0] is \\n{len(part_content2)}')\n","\n","print(f'current_staff1_clef:{current_staff1_clef}\\ncurrent_staff2_clef:{current_staff2_clef}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#generate XML\n","from yoloToxml.yoloToxml import musicData2XML\n","import xml.etree.ElementTree as ET\n","from xml.dom import minidom\n","\n","\n","#for staff1\n","\n","part_et = ET.Element('part')\n","part_et.attrib = {'id':'P1'}\n","part_et_1 = musicData2XML(part_et, dictionary_for_ET_staff1)\n","\n","xmlstr_1 = minidom.parseString(ET.tostring(part_et_1)).toprettyxml(indent=\"   \")\n","\n","#to delete <?xml version=\"1.0\"　?> in line 1\n","xmlstr_1 = xmlstr_1[23:]\n","            \n","\n","#read template.xml to prepare part_et XML data and generate the whole XML\n","wholeXML_staff1_text = \"\"\n","with open(\"/content/img2xml/bfaaap/yoloToxml/template.xml\", 'r') as f:\n","    template_text = f.read()\n","    wholeXML_staff1_text = template_text +'\\n' + xmlstr_1 +'\\n</score-partwise>'\n","\n","#save the resulting xml in ./xml/ directory\n","FILE_DIR_PATH\n","new_dir_path = FILE_DIR_PATH + '/xml'\n","os.makedirs(new_dir_path, exist_ok=True)\n","new_xml_filepath = new_dir_path + '/' + FILE_BASENAME_WITHOUTEXT + '_staff1.xml'\n","with open(new_xml_filepath, 'w') as f:\n","    f.write(wholeXML_staff1_text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#for staff2\n","\n","part_et = ET.Element('part')\n","part_et.attrib = {'id':'P1'}\n","part_et_2 = musicData2XML(part_et, dictionary_for_ET_staff2)\n","\n","xmlstr_2 = minidom.parseString(ET.tostring(part_et_2)).toprettyxml(indent=\"   \")\n","\n","#1行目の<?xml version=\"1.0\"　?>を除く：　　結合するため\n","xmlstr_2 = xmlstr_2[23:]\n","# print(xmlstr_1)\n","# print(f'XML化した結果データは{xmlstr_1}')                \n","\n","#template.xmlファイルを読み込んで得られたpart_etのXMLデータと結合して全体XMLを作る\n","wholeXML_staff2_text = \"\"\n","with open(\"/content/img2xml/bfaaap/yoloToxml/template.xml\", 'r') as f:\n","    template_text = f.read()\n","    wholeXML_staff2_text = template_text +'\\n' + xmlstr_2 +'\\n</score-partwise>'\n","\n","#save the resulting xml in ./xml/ directory\n","FILE_DIR_PATH\n","new_dir_path = FILE_DIR_PATH + '/xml'\n","os.makedirs(new_dir_path, exist_ok=True)\n","new_xml_filepath = new_dir_path + '/' + FILE_BASENAME_WITHOUTEXT + '_staff2.xml'\n","with open(new_xml_filepath, 'w') as f:\n","    f.write(wholeXML_staff2_text)\n"]},{"cell_type":"markdown","metadata":{},"source":["# download the resulting xml file from /content/img2xml/bfaaap/musicdata/test0/xml/\n","\n","### An Web [img2xml](https://saaipf.com/app/upload) application is available.\n","\n","### Use, for instance, [MuseScore](https://musescore.org/), [Sibelius First](https://my.avid.com/get/sibelius-first), or [xml2sound](https://saaipf.com/app2/upload) to produce a sound from the resulting xml file.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}